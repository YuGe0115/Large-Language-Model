# 大语言模型常用评价指标

## 1. 困惑度（Perplexity, PPL）

- **定义**：衡量语言模型预测下一个词的能力，数值越低说明模型越好。  

- **公式**：  
  $$
  PPL = \exp \left( - \frac{1}{N} \sum_{i=1}^{N} \log p(w_i | w_{<i}) \right)
  $$
  其中，$N$ 为语料长度，$p(w_i | w_{<i})$ 为模型预测下一个词的概率。

- **直观理解**：PPL 可以理解为模型在预测下一个词时平均有多少种选择。

- **代码示例（PyTorch）**：

  ```python
  import torch
  import torch.nn.functional as F
  
  def calculate_perplexity(logits, labels):
      """
      logits: [batch_size, seq_len, vocab_size]
      labels: [batch_size, seq_len]
      """
      loss = F.cross_entropy(
          logits.view(-1, logits.size(-1)), 
          labels.view(-1), 
          reduction="mean"
      )
      perplexity = torch.exp(loss)
      return perplexity.item()
  
  # 假设有模型输出
  dummy_logits = torch.randn(2, 5, 10000)  # batch=2, seq_len=5, vocab=10000
  dummy_labels = torch.randint(0, 10000, (2, 5))
  print("Perplexity:", calculate_perplexity(dummy_logits, dummy_labels))
  ```

---

## 2. BLEU (Bilingual Evaluation Understudy)

- **用途**：常用于机器翻译、摘要生成，衡量生成文本与参考文本之间的 n-gram 匹配程度。

- **范围**：0 ~ 1（或 0 ~ 100），越高越好。

- **缺点**：不考虑语义，仅匹配表面 n-gram。

- **代码示例（NLTK）**：

  ```python
  from nltk.translate.bleu_score import sentence_bleu
  
  reference = [["今天", "天气", "很好"]]
  candidate = ["今天天气不错"]
  
  score = sentence_bleu(reference, candidate)
  print("BLEU score:", score)
  ```

---

## 3. ROUGE (Recall-Oriented Understudy for Gisting Evaluation)

- **用途**：主要用于摘要生成，衡量生成文本与参考文本的 **召回率** 和 **重叠程度**。

- **常见指标**：

  - ROUGE-N：基于 n-gram 的重叠
  - ROUGE-L：基于最长公共子序列（LCS）

- **代码示例（rouge-score 库）**：

  ```python
  from rouge_score import rouge_scorer
  
  scorer = rouge_scorer.RougeScorer(["rouge1", "rougeL"], use_stemmer=True)
  scores = scorer.score("今天天气不错", "今天的天气很好")
  
  print(scores)
  ```

---

## 4. METEOR (Metric for Evaluation of Translation with Explicit ORdering)

- **用途**：改进 BLEU，考虑词形变化、同义词和词序。

- **范围**：0 ~ 1，越高越好。

- **特点**：比 BLEU 更贴近人工评价。

- **代码示例（NLTK）**：

  ```python
  from nltk.translate.meteor_score import meteor_score
  
  reference = ["今天 天气 很好"]
  candidate = "今天天气不错"
  
  score = meteor_score(reference, candidate)
  print("METEOR:", score)
  ```

---

## 5. BERTScore

- **用途**：基于 BERT 等预训练模型计算文本的语义相似度。

- **优势**：考虑上下文语义，比 BLEU/ROUGE 更接近人类评价。

- **代码示例（bert-score 库）**：

  ```python
  from bert_score import score
  
  cands = ["今天天气不错"]
  refs = ["今天的天气很好"]
  
  P, R, F1 = score(cands, refs, lang="zh", verbose=True)
  print(f"BERTScore F1: {F1.mean().item():.4f}")
  ```

---

## 总结

- **语言模型内部评价**：Perplexity  
- **文本生成任务评价**：BLEU, ROUGE, METEOR  
- **语义相关性评价**：BERTScore  
- **最终标准**：人工评价 ！